# -*- coding: utf-8 -*-
"""sms-text-classifier.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1viGfHhJTmFvg6_DUunyPLVBqekl_Dmh0

# SMS Text Classifier Using Neural Networks

## 1. Data Loading & Exploration
"""

import pandas as pd
import tensorflow as tf
from tensorflow import keras
import matplotlib.pyplot as plt
from sklearn.model_selection import train_test_split
from tensorflow.keras.preprocessing.text import Tokenizer
from tensorflow.keras.preprocessing.sequence import pad_sequences

# Load data
train_data = pd.read_csv('train-data.csv')
test_data = pd.read_csv('valid-data.csv')

# Convert labels to binary
train_data['type'] = train_data['type'].map({'ham': 0, 'spam': 1})
test_data['type'] = test_data['type'].map({'ham': 0, 'spam': 1})

# Explore data
print(train_data.head())
print("\nClass distribution:")
print(train_data['type'].value_counts())

"""## 2. Text Preprocessing

"""

def preprocess_text(data, max_words=10000, max_len=100):
    """Preprocess text data and return tokenizer and sequences"""
    tokenizer = Tokenizer(num_words=max_words, oov_token='<OOV>')
    tokenizer.fit_on_texts(data['text'])

    sequences = tokenizer.texts_to_sequences(data['text'])
    padded = pad_sequences(sequences, maxlen=max_len, truncating='post')

    return tokenizer, padded, sequences

# Preprocess training and test data
max_words = 1000
max_len = 50
tokenizer, train_padded, _ = preprocess_text(train_data, max_words, max_len)
_, test_padded, _ = preprocess_text(test_data, max_words, max_len)

# Get labels
train_labels = train_data['type'].values
test_labels = test_data['type'].values

"""## 3. Model Building

"""

def build_model(vocab_size, embedding_dim=16, max_len=50):
    """Build and compile text classification model"""
    model = keras.Sequential([
        keras.layers.Embedding(vocab_size, embedding_dim, input_length=max_len),
        keras.layers.GlobalAveragePooling1D(),
        keras.layers.Dense(24, activation='relu'),
        keras.layers.Dense(1, activation='sigmoid')
    ])

    model.compile(
        loss='binary_crossentropy',
        optimizer='adam',
        metrics=['accuracy']
    )

    return model

# Build model
model = build_model(max_words, max_len=max_len)
model.summary()

"""## 4. Training & Evaluation

"""

# Train model
history = model.fit(
    train_padded,
    train_labels,
    epochs=10,
    validation_data=(test_padded, test_labels),
    verbose=2
)

# Plot training history
def plot_history(history):
    plt.plot(history.history['accuracy'], label='accuracy')
    plt.plot(history.history['val_accuracy'], label='val_accuracy')
    plt.xlabel('Epoch')
    plt.ylabel('Accuracy')
    plt.ylim([0, 1])
    plt.legend()
    plt.show()

plot_history(history)

# Evaluate model
loss, accuracy = model.evaluate(test_padded, test_labels)
print(f'\nTest accuracy: {accuracy:.2%}')

"""## 5. Prediction Function

"""

def predict_message(message):
    """Predict if message is ham or spam"""
    # Preprocess input
    sequence = tokenizer.texts_to_sequences([message])
    padded = pad_sequences(sequence, maxlen=max_len, truncating='post')

    # Make prediction
    prediction = model.predict(padded)[0][0]
    label = 'spam' if prediction >= 0.5 else 'ham'

    return [prediction, label]

# Test prediction
test_messages = [
    "Free entry in 2 a wkly comp to win FA Cup final tkts 21st May 2005",
    "Hey there, just checking in to see how you're doing"
]

for msg in test_messages:
    print(f"\nMessage: {msg}")
    prediction = predict_message(msg)
    print(f"Prediction: {prediction[0]:.4f} ({prediction[1]})")

"""## 6. Explanation

- **Model Type**: Neural network with embedding and dense layers for text classification
- **Input**: Processes SMS messages by converting words to numerical tokens
- **Output**: Predicts probability (0-1) of message being spam
- **Key Features**: Handles variable-length texts, learns word relationships

---
"""