{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Book Recommendation Engine Using KNN"
      ],
      "metadata": {
        "id": "vMQd9hzaoGRc"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Project Structure\n",
        "\n",
        "1. Data Loading & Exploration\n",
        "\n",
        "2. Data Preprocessing\n",
        "\n",
        "3. Model Building\n",
        "\n",
        "4. Recommendation Function\n",
        "\n",
        "5. Testing"
      ],
      "metadata": {
        "id": "4O3ESMCbq8Ob"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 01- Import Libraries & Load Dataset"
      ],
      "metadata": {
        "id": "JU6VMHoVriS0"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oJBTAZRWoCeJ",
        "outputId": "dbd0575d-453d-47d4-922f-3762cb103e76"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-2941081801.py:10: DtypeWarning: Columns (3) have mixed types. Specify dtype option on import or set low_memory=False.\n",
            "  books = pd.read_csv('BX-Books.csv', sep=';', on_bad_lines='skip', encoding=\"latin-1\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Books shape: (271360, 8)\n",
            "Users shape: (278858, 3)\n",
            "Ratings shape: (1149780, 3)\n",
            "\n",
            "Books sample:\n",
            "         ISBN                                         Book-Title  \\\n",
            "0  0195153448                                Classical Mythology   \n",
            "1  0002005018                                       Clara Callan   \n",
            "2  0060973129                               Decision in Normandy   \n",
            "3  0374157065  Flu: The Story of the Great Influenza Pandemic...   \n",
            "4  0393045218                             The Mummies of Urumchi   \n",
            "\n",
            "            Book-Author Year-Of-Publication                   Publisher  \\\n",
            "0    Mark P. O. Morford                2002     Oxford University Press   \n",
            "1  Richard Bruce Wright                2001       HarperFlamingo Canada   \n",
            "2          Carlo D'Este                1991             HarperPerennial   \n",
            "3      Gina Bari Kolata                1999        Farrar Straus Giroux   \n",
            "4       E. J. W. Barber                1999  W. W. Norton &amp; Company   \n",
            "\n",
            "                                         Image-URL-S  \\\n",
            "0  http://images.amazon.com/images/P/0195153448.0...   \n",
            "1  http://images.amazon.com/images/P/0002005018.0...   \n",
            "2  http://images.amazon.com/images/P/0060973129.0...   \n",
            "3  http://images.amazon.com/images/P/0374157065.0...   \n",
            "4  http://images.amazon.com/images/P/0393045218.0...   \n",
            "\n",
            "                                         Image-URL-M  \\\n",
            "0  http://images.amazon.com/images/P/0195153448.0...   \n",
            "1  http://images.amazon.com/images/P/0002005018.0...   \n",
            "2  http://images.amazon.com/images/P/0060973129.0...   \n",
            "3  http://images.amazon.com/images/P/0374157065.0...   \n",
            "4  http://images.amazon.com/images/P/0393045218.0...   \n",
            "\n",
            "                                         Image-URL-L  \n",
            "0  http://images.amazon.com/images/P/0195153448.0...  \n",
            "1  http://images.amazon.com/images/P/0002005018.0...  \n",
            "2  http://images.amazon.com/images/P/0060973129.0...  \n",
            "3  http://images.amazon.com/images/P/0374157065.0...  \n",
            "4  http://images.amazon.com/images/P/0393045218.0...  \n",
            "\n",
            "Ratings sample:\n",
            "   User-ID        ISBN  Book-Rating\n",
            "0   276725  034545104X            0\n",
            "1   276726  0155061224            5\n",
            "2   276727  0446520802            0\n",
            "3   276729  052165615X            3\n",
            "4   276729  0521795028            6\n",
            "\n",
            "Users sample:\n",
            "   User-ID                            Location   Age\n",
            "0        1                  nyc, new york, usa   NaN\n",
            "1        2           stockton, california, usa  18.0\n",
            "2        3     moscow, yukon territory, russia   NaN\n",
            "3        4           porto, v.n.gaia, portugal  17.0\n",
            "4        5  farnborough, hants, united kingdom   NaN\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "from scipy.sparse import csr_matrix\n",
        "from sklearn.neighbors import NearestNeighbors\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "# Load data with updated parameters\n",
        "try:\n",
        "    books = pd.read_csv('BX-Books.csv', sep=';', on_bad_lines='skip', encoding=\"latin-1\")\n",
        "    users = pd.read_csv('BX-Users.csv', sep=';', on_bad_lines='skip', encoding=\"latin-1\")\n",
        "    ratings = pd.read_csv('BX-Book-Ratings.csv', sep=';', on_bad_lines='skip', encoding=\"latin-1\")\n",
        "except FileNotFoundError:\n",
        "    # If files aren't in current directory, try loading from URL\n",
        "    import io\n",
        "    import requests\n",
        "\n",
        "    def load_from_url(url):\n",
        "        response = requests.get(url)\n",
        "        return pd.read_csv(io.StringIO(response.text), sep=';', on_bad_lines='skip', encoding=\"latin-1\")\n",
        "\n",
        "    books_url = \"https://raw.githubusercontent.com/zygmuntz/goodbooks-10k/master/samples/bx-books.csv\"\n",
        "    users_url = \"https://raw.githubusercontent.com/zygmuntz/goodbooks-10k/master/samples/bx-users.csv\"\n",
        "    ratings_url = \"https://raw.githubusercontent.com/zygmuntz/goodbooks-10k/master/samples/bx-book-ratings.csv\"\n",
        "\n",
        "    books = load_from_url(books_url)\n",
        "    users = load_from_url(users_url)\n",
        "    ratings = load_from_url(ratings_url)\n",
        "\n",
        "# Explore data shapes\n",
        "print(f\"Books shape: {books.shape}\")\n",
        "print(f\"Users shape: {users.shape}\")\n",
        "print(f\"Ratings shape: {ratings.shape}\")\n",
        "\n",
        "# Show sample data\n",
        "print(\"\\nBooks sample:\")\n",
        "print(books.head())\n",
        "print(\"\\nRatings sample:\")\n",
        "print(ratings.head())\n",
        "print(\"\\nUsers sample:\")\n",
        "print(users.head())"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 02- Data Preprocessing"
      ],
      "metadata": {
        "id": "cJ1ToE4Or-xQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def preprocess_data(ratings, users, books, min_book_ratings=100, min_user_ratings=200):\n",
        "    \"\"\"Preprocess data by filtering based on rating thresholds\"\"\"\n",
        "    # Count ratings per user and book\n",
        "    user_rating_counts = ratings['User-ID'].value_counts()\n",
        "    book_rating_counts = ratings['ISBN'].value_counts()\n",
        "\n",
        "    # Filter users and books\n",
        "    valid_users = user_rating_counts[user_rating_counts >= min_user_ratings].index\n",
        "    valid_books = book_rating_counts[book_rating_counts >= min_book_ratings].index\n",
        "\n",
        "    # Apply filters\n",
        "    filtered_ratings = ratings[\n",
        "        (ratings['User-ID'].isin(valid_users)) &\n",
        "        (ratings['ISBN'].isin(valid_books))\n",
        "    ]\n",
        "\n",
        "    # Merge with book data\n",
        "    final_data = filtered_ratings.merge(books, on='ISBN')\n",
        "\n",
        "    # Create pivot table\n",
        "    book_pivot = final_data.pivot_table(\n",
        "        index='Book-Title',\n",
        "        columns='User-ID',\n",
        "        values='Book-Rating'\n",
        "    ).fillna(0)\n",
        "\n",
        "    # Convert to sparse matrix\n",
        "    book_sparse = csr_matrix(book_pivot.values)\n",
        "\n",
        "    return book_pivot, book_sparse\n",
        "\n",
        "book_pivot, book_sparse = preprocess_data(ratings, users, books)"
      ],
      "metadata": {
        "id": "PIDQy5xWsAHK"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 03- Model Building"
      ],
      "metadata": {
        "id": "oQuBhSALsl2c"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def build_knn_model(sparse_matrix, n_neighbors=5, metric='cosine'):\n",
        "    \"\"\"Build and fit KNN model\"\"\"\n",
        "    model = NearestNeighbors(\n",
        "        n_neighbors=n_neighbors+1,  # +1 to exclude the book itself\n",
        "        algorithm='auto',\n",
        "        metric=metric\n",
        "    )\n",
        "    model.fit(sparse_matrix)\n",
        "    return model\n",
        "\n",
        "knn_model = build_knn_model(book_sparse)"
      ],
      "metadata": {
        "id": "2Hrh4dXksmfZ"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 04- Recommendation Function"
      ],
      "metadata": {
        "id": "igs9Q8jxspjK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def get_recommends(book_title, model, pivot_table):\n",
        "    \"\"\"Get book recommendations for given title\"\"\"\n",
        "    try:\n",
        "        # Find book index\n",
        "        book_idx = np.where(pivot_table.index == book_title)[0][0]\n",
        "\n",
        "        # Get distances and indices of nearest neighbors\n",
        "        distances, indices = model.kneighbors(\n",
        "            pivot_table.iloc[book_idx, :].values.reshape(1, -1))\n",
        "\n",
        "        # Prepare recommendations\n",
        "        recommended_books = []\n",
        "        for i in range(1, len(indices.flatten())):  # Skip first (itself)\n",
        "            recommended_books.append([\n",
        "                pivot_table.index[indices.flatten()[i]],\n",
        "                distances.flatten()[i]\n",
        "            ])\n",
        "\n",
        "        # Sort by distance (closest first)\n",
        "        recommended_books = sorted(recommended_books, key=lambda x: x[1], reverse=True)\n",
        "\n",
        "        return [book_title, recommended_books]\n",
        "\n",
        "    except IndexError:\n",
        "        return f\"Book '{book_title}' not found in dataset\"\n",
        "\n",
        "# Test function\n",
        "print(get_recommends(\"The Queen of the Damned (Vampire Chronicles (Paperback))\", knn_model, book_pivot))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sSjbjQz3sqI3",
        "outputId": "83bd3831-9847-4787-ae4e-3a617de77592"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['The Queen of the Damned (Vampire Chronicles (Paperback))', [['Catch 22', np.float64(0.7939835419270879)], ['The Witching Hour (Lives of the Mayfair Witches)', np.float64(0.7448657003312193)], ['Interview with the Vampire', np.float64(0.7345068863988313)], ['The Tale of the Body Thief (Vampire Chronicles (Paperback))', np.float64(0.5376338446489461)], ['The Vampire Lestat (Vampire Chronicles, Book II)', np.float64(0.5178411864186413)]]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "from scipy.sparse import csr_matrix\n",
        "from sklearn.neighbors import NearestNeighbors\n",
        "\n",
        "class BookRecommender:\n",
        "    def __init__(self, ratings_path, books_path, users_path):\n",
        "        self.ratings, self.books, self.users = self._load_data(ratings_path, books_path, users_path)\n",
        "        self.book_pivot, self.book_sparse = None, None\n",
        "        self.model = None\n",
        "\n",
        "    def _load_data(self, ratings_path, books_path, users_path):\n",
        "        \"\"\"Load and merge datasets using updated pandas parameters\"\"\"\n",
        "        # Use on_bad_lines instead of error_bad_lines for newer pandas versions\n",
        "        load_params = {\n",
        "            'sep': ';',\n",
        "            'encoding': 'latin-1',\n",
        "            'on_bad_lines': 'skip'  # Changed from error_bad_lines\n",
        "        }\n",
        "\n",
        "        try:\n",
        "            books = pd.read_csv(books_path, **load_params)\n",
        "            users = pd.read_csv(users_path, **load_params)\n",
        "            ratings = pd.read_csv(ratings_path, **load_params)\n",
        "            return ratings, books, users\n",
        "        except Exception as e:\n",
        "            print(f\"Error loading data: {str(e)}\")\n",
        "            # Try loading from URL if local files fail\n",
        "            return self._load_backup_data()\n",
        "\n",
        "    def _load_backup_data(self):\n",
        "        \"\"\"Load backup data from URLs if local files fail\"\"\"\n",
        "        print(\"Attempting to load data from URLs...\")\n",
        "        base_url = \"https://raw.githubusercontent.com/zygmuntz/goodbooks-10k/master/samples/\"\n",
        "        urls = {\n",
        "            'ratings': base_url + \"bx-book-ratings.csv\",\n",
        "            'books': base_url + \"bx-books.csv\",\n",
        "            'users': base_url + \"bx-users.csv\"\n",
        "        }\n",
        "\n",
        "        load_params = {\n",
        "            'sep': ';',\n",
        "            'encoding': 'latin-1',\n",
        "            'on_bad_lines': 'skip'\n",
        "        }\n",
        "\n",
        "        books = pd.read_csv(urls['books'], **load_params)\n",
        "        users = pd.read_csv(urls['users'], **load_params)\n",
        "        ratings = pd.read_csv(urls['ratings'], **load_params)\n",
        "        return ratings, books, users\n",
        "\n",
        "    def preprocess(self, min_book_ratings=100, min_user_ratings=200):\n",
        "        \"\"\"Preprocess data with rating thresholds\"\"\"\n",
        "        # Filter users and books\n",
        "        user_counts = self.ratings['User-ID'].value_counts()\n",
        "        book_counts = self.ratings['ISBN'].value_counts()\n",
        "\n",
        "        valid_users = user_counts[user_counts >= min_user_ratings].index\n",
        "        valid_books = book_counts[book_counts >= min_book_ratings].index\n",
        "\n",
        "        filtered_ratings = self.ratings[\n",
        "            (self.ratings['User-ID'].isin(valid_users)) &\n",
        "            (self.ratings['ISBN'].isin(valid_books))\n",
        "        ]\n",
        "\n",
        "        # Create pivot table\n",
        "        self.book_pivot = filtered_ratings.merge(\n",
        "            self.books, on='ISBN'\n",
        "        ).pivot_table(\n",
        "            index='Book-Title',\n",
        "            columns='User-ID',\n",
        "            values='Book-Rating'\n",
        "        ).fillna(0)\n",
        "\n",
        "        self.book_sparse = csr_matrix(self.book_pivot.values)\n",
        "\n",
        "    def train_model(self, n_neighbors=5, metric='cosine'):\n",
        "        \"\"\"Train KNN model\"\"\"\n",
        "        if self.book_sparse is None:\n",
        "            raise ValueError(\"Preprocess data first\")\n",
        "\n",
        "        self.model = NearestNeighbors(\n",
        "            n_neighbors=n_neighbors+1,\n",
        "            algorithm='auto',\n",
        "            metric=metric\n",
        "        )\n",
        "        self.model.fit(self.book_sparse)\n",
        "\n",
        "    def get_recommends(self, book_title):\n",
        "        \"\"\"Get recommendations for a book\"\"\"\n",
        "        if self.model is None or self.book_pivot is None:\n",
        "            raise ValueError(\"Model not trained or data not preprocessed\")\n",
        "\n",
        "        try:\n",
        "            book_idx = np.where(self.book_pivot.index == book_title)[0][0]\n",
        "            distances, indices = self.model.kneighbors(\n",
        "                self.book_pivot.iloc[book_idx, :].values.reshape(1, -1))\n",
        "\n",
        "            recommendations = [\n",
        "                [self.book_pivot.index[i], d]\n",
        "                for i, d in zip(indices.flatten()[1:], distances.flatten()[1:])\n",
        "            ]\n",
        "\n",
        "            return [book_title, sorted(recommendations, key=lambda x: x[1], reverse=True)]\n",
        "\n",
        "        except IndexError:\n",
        "            return f\"Book '{book_title}' not found in dataset\"\n",
        "\n",
        "# Usage example with error handling\n",
        "try:\n",
        "    recommender = BookRecommender(\n",
        "        'BX-Book-Ratings.csv',\n",
        "        'BX-Books.csv',\n",
        "        'BX-Users.csv'\n",
        "    )\n",
        "    recommender.preprocess()\n",
        "    recommender.train_model()\n",
        "\n",
        "    test_book = \"The Queen of the Damned (Vampire Chronicles (Paperback))\"\n",
        "    print(recommender.get_recommends(test_book))\n",
        "\n",
        "except Exception as e:\n",
        "    print(f\"Error in recommendation system: {str(e)}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PjHveSNGswnv",
        "outputId": "32c40ef1-90d0-4ee6-9f9d-a0c0c2d60ce5"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-1533142611.py:22: DtypeWarning: Columns (3) have mixed types. Specify dtype option on import or set low_memory=False.\n",
            "  books = pd.read_csv(books_path, **load_params)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['The Queen of the Damned (Vampire Chronicles (Paperback))', [['Catch 22', np.float64(0.7939835419270879)], ['The Witching Hour (Lives of the Mayfair Witches)', np.float64(0.7448657003312193)], ['Interview with the Vampire', np.float64(0.7345068863988313)], ['The Tale of the Body Thief (Vampire Chronicles (Paperback))', np.float64(0.5376338446489461)], ['The Vampire Lestat (Vampire Chronicles, Book II)', np.float64(0.5178411864186413)]]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 05- Testing"
      ],
      "metadata": {
        "id": "dWz_j1_Xs2qd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Test with the required book\n",
        "test_book = \"The Queen of the Damned (Vampire Chronicles (Paperback))\"\n",
        "print(recommender.get_recommends(test_book))\n",
        "\n",
        "# Test with random books\n",
        "for book in np.random.choice(recommender.book_pivot.index, 3):\n",
        "    print(\"\\nRecommendations for:\", book)\n",
        "    print(recommender.get_recommends(book))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "d4K3dpVos5Xh",
        "outputId": "d6c09ae1-21b1-472a-d10c-706f21dbc8c6"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['The Queen of the Damned (Vampire Chronicles (Paperback))', [['Catch 22', np.float64(0.7939835419270879)], ['The Witching Hour (Lives of the Mayfair Witches)', np.float64(0.7448657003312193)], ['Interview with the Vampire', np.float64(0.7345068863988313)], ['The Tale of the Body Thief (Vampire Chronicles (Paperback))', np.float64(0.5376338446489461)], ['The Vampire Lestat (Vampire Chronicles, Book II)', np.float64(0.5178411864186413)]]]\n",
            "\n",
            "Recommendations for: Southern Cross\n",
            "['Southern Cross', [['Cradle and All', np.float64(0.7611771486505596)], ['Unnatural Exposure', np.float64(0.7282497349087003)], ['The Body Farm', np.float64(0.7245286615411648)], ['Black Friday', np.float64(0.6070886378513438)], ['Isle of Dogs', np.float64(0.5439673619663369)]]]\n",
            "\n",
            "Recommendations for: Seabiscuit\n",
            "['Seabiscuit', [['Midwives: A Novel', np.float64(0.7740154179350087)], ['STONES FROM THE RIVER', np.float64(0.7728723983662207)], ['Midnight in the Garden of Good and Evil', np.float64(0.7532707322489147)], ['The Mulberry Tree', np.float64(0.748992565581007)], ['The Hundred Secret Senses', np.float64(0.7123004857457995)]]]\n",
            "\n",
            "Recommendations for: Eats, Shoots &amp; Leaves: The Zero Tolerance Approach to Punctuation\n",
            "['Eats, Shoots &amp; Leaves: The Zero Tolerance Approach to Punctuation', [['The Temple of My Familiar', np.float64(0.7929697117192669)], ['Tears of the Giraffe (No.1 Ladies Detective Agency)', np.float64(0.7845751024872697)], [\"Ender's Game (Ender Wiggins Saga (Paperback))\", np.float64(0.7826599851598155)], ['The Hours: A Novel', np.float64(0.7790514147795367)], [\"Big Cherry Holler: A Big Stone Gap Novel (Ballantine Reader's Circle)\", np.float64(0.769486277669488)]]]\n"
          ]
        }
      ]
    }
  ]
}